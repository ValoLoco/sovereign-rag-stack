# LLM Provider Configuration
# Choose: anthropic, ollama
LLM_PROVIDER=anthropic

# Anthropic API
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Ollama Configuration (for local LLM)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.3

# Memory Layer
MEM0_USE_LOCAL=true
VECTOR_DB_PATH=C:\\BUENATURA\\vectors
EMBEDDINGS_CACHE_DIR=C:\\BUENATURA\\.cache\\embeddings

# Clerk Authentication (Web Mode)
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_...
CLERK_SECRET_KEY=sk_test_...

# Vercel Postgres (Web Mode)
POSTGRES_URL=postgres://...
POSTGRES_PRISMA_URL=postgres://...
POSTGRES_URL_NON_POOLING=postgres://...

# Vercel Blob Storage (Web Mode)
BLOB_READ_WRITE_TOKEN=vercel_blob_...

# GitHub Sync
GITHUB_TOKEN=ghp_...
GITHUB_REPO=ValoLoco/sovereign-rag-stack
SYNC_TOKEN=your_secure_random_token
SYNC_INTERVAL=900

# Local Mode Paths
LOCAL_DATA_DIR=C:\\BUENATURA
RAG_DATA_DIR=C:\\BUENATURA\\knowledge
RAG_DB_DIR=C:\\BUENATURA\\vectors
